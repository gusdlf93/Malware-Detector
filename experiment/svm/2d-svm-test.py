import cv2
import os, glob, numpy as np
from sklearn.model_selection import train_test_split
import cv2
from keras.utils import np_utils
from PIL import Image
import PIL
import os, glob, numpy as np
from keras.models import Sequential
from keras.layers import Conv2D,Conv3D, MaxPooling2D, Dense, Flatten, Dropout
from keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
import keras.backend.tensorflow_backend as K
from keras.optimizers import SGD, RMSprop
import tensorflow as tf
from keras import optimizers
from keras.utils import np_utils
from keras.applications.inception_v3 import InceptionV3
import sys
import sklearn
from sklearn.metrics import precision_recall_curve
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, average_precision_score
from keras.models import Sequential, Model

def recursive_find(path, path_list):
    # 재귀적으로 함수의 절대 경로를 출력합니다.
    # path는 탐색을 시작할 폴더, path_list는 return 해줄 절대 경로의 list입니다.
    files = os.listdir(path)

    for file in files:
        full_path = os.path.join(path, file)
        recursive_find(full_path, path_list) if os.path.isdir(full_path) else path_list.append(full_path)

    return path_list

def get_data(path):
    img = []
    label = []
    for i_path in path:
        abs_path = i_path.split('\\')

        temp_img = Image.open(i_path)
        temp_img = temp_img.convert("L")
        #         temp_img = temp_img.resize((image_w, image_h), resample=PIL.Image.NEAREST)
        temp_img = temp_img.resize((image_w, image_h), resample=PIL.Image.BICUBIC)
        #         temp_img = temp_img.resize((image_w, image_h), resample=PIL.Image.BILINEAR)
        #        PILIMG default가 bicubic이기 때문에 bicubic으로 한겁니다.
        #         temp_img = cv2.imread(i_path, cv2.IMREAD_GRAYSCALE)  if color == 1 else \
        #         cv2.imread(i_path, cv2.IMREAD_COLOR)
        #         temp_img = cv2.resize(temp_img, (image_h, image_w), cv2.INTER_CUBIC)
        #         temp_img = cv2.resize(temp_img, (image_h, image_w), cv2.INTER_LINEAR)
        #         temp_img = cv2.resize(temp_img, (image_h, image_w), cv2.cv2.INTER_NEAREST)

        img.append(np.array(temp_img))
        label.append(abs_path[-2])

    # img = np.asarray(img)
    # img = img.reshape(img.shape[0] ,img.shape[1], img.shape[2], color)#if color
    label = [target[i] for i in label]
    label = np.asarray(label)
    label = np_utils.to_categorical(label)
    return img, label

def make_data(path):
    path_list = []
    data_path_list = recursive_find(path, path_list)
    return get_data(data_path_list)

    # image_w, image_h, color = 64, 64, 1

def load_model(path):
    img_input = Input(shape=(image_w, image_h, 1))
    x = Conv2D(64, kernel_size=(3, 3), input_shape = (image_w, image_h, 1), activation='relu')(img_input)
    x = Conv2D(128, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Conv2D(256, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(0.5)(x)
    x = Conv2D(512, (3, 3), activation='relu')(x)
    _x = GlobalAveragePooling2D()(x)
    x = Dropout(0.5)(_x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = Dense(20, activation='softmax')(x)
    org_model = Model(img_input, x)
    org_model.load_weights(path)
    model = Model(img_input, _x)
    return model

image_w, image_h, color = 64, 64, 1
target = dict([[name, _] for _, name in enumerate(os.listdir(r'D:\android\Data\dex_20'))])

X, Y = make_data(r'D:\android\Data\dex_20')

X = np.array(X)
y = np.array(Y)

X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.2,random_state = 0)
xy = (X_train, X_test, y_train, y_test)

print("ok", len(y))

#X_train = X_train.reshape(X_train.shape[0], 64, 64, 1).astype('float32') / 255
#X_test = X_test.reshape(X_test.shape[0], 64, 64, 1).astype('float32') / 255

X_train = X_train.reshape(X_train.shape[0], image_h, image_w, 1).astype('float32') / 255
X_test = X_test.reshape(X_test.shape[0], image_h, image_w, 1).astype('float32') / 255
from keras.layers import *

with K.tf_ops.device('/device:GPU:0'):
    #img_input = Input(shape=(None, 1))

    img_input = Input(shape=(image_w, image_h, 1))
    x = Conv2D(64, kernel_size=(3, 3), input_shape = (image_w, image_h, 1), activation='relu')(img_input)
    x = Conv2D(128, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Conv2D(256, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(0.5)(x)
    x = Conv2D(512, (3, 3), activation='relu')(x)
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.5)(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = Dense(20, activation='softmax')(x)
    model = Model(img_input, x)

    model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])

    model_dir = r'D:\android\Model'
    if not os.path.exists(model_dir):
        os.mkdir(model_dir)

    modelName = model_dir + r'\basic.model'

    checkpointer = ModelCheckpoint(filepath=modelName, monitor='val_loss', verbose=20, save_best_only=True)

    early_stopping = EarlyStopping(monitor='val_loss', patience=20)

    model.summary()

    import time
    history = model.fit(X_train, y_train, epochs=100, batch_size=5, validation_split=0.15, callbacks=[early_stopping, checkpointer])

    from sklearn import svm

    model = load_model(modelName)
    X_train = model.predict(X_train).reshape(len(X_train), 512)
    X_test = model.predict(X_test).reshape(len(X_test), 512)

    clf = svm.SVC(kernel='linear')

    from sklearn.datasets import make_blobs

    X, y = make_blobs(n_samples=40, centers=2, random_state=20)

    clf.fit(X_train, np.argmax(y_train, axis=1))

    y_pred_class = clf.predict(X_test)
    y_test_class = np.argmax(y_test, axis=1)

    print(classification_report(y_test_class, y_pred_class, digits=3))

    # For each class
    precision = dict()
    recall = dict()
    average_precision = dict()
    for i in range(20):
        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],
                                                            y_pred[:, i])
        average_precision[i] = average_precision_score(y_test[:, i], y_pred[:, i])

    # A "micro-average": quantifying score on all classes jointly
    precision["micro"], recall["micro"], _ = precision_recall_curve(y_test.ravel(),
                                                                    y_pred.ravel())
    average_precision["micro"] = average_precision_score(y_test, y_pred,
                                                         average="micro")
    print('Average precision score, micro-averaged over all classes: {0:0.2f}'
          .format(average_precision["micro"]))

    plt.figure()
    plt.step(recall['micro'], precision['micro'], where='post')

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.ylim([0.0, 1.05])
    plt.xlim([0.0, 1.0])
    plt.title('Average precision score, micro-averaged over all classes: AP={0:0.2f}'.format(average_precision["micro"]))
